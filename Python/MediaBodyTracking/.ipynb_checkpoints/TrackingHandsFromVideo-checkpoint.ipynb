{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c37085",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c91251df378e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdrawingModule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mhandsModule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhands\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmp_objectron\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjectron\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mp' is not defined"
     ]
    }
   ],
   "source": [
    "#https://www.youtube.com/watch?v=NZde8Xt78Iw\n",
    "import cv2\n",
    "import mediapipe\n",
    " \n",
    "drawingModule = mediapipe.solutions.drawing_utils\n",
    "handsModule = mediapipe.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe51a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all videos in mediafolder\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"./MediaToAnalyze/\"\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e5fe30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440.0 1080.0\n"
     ]
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(mypath+onlyfiles[0])\n",
    "frameWidth = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "frameHeight = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "print(frameWidth, frameHeight )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8dfb4e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only for testing (not writing points)\n",
    "with handsModule.Hands(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.9, max_num_hands=6) as hands:\n",
    "    while (True):\n",
    "         # Hand landmarks estimation on each frame\n",
    "        ret, frame = capture.read()\n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        if results.multi_hand_landmarks != None:\n",
    "            for handLandmarks in results.multi_hand_landmarks:\n",
    "                drawingModule.draw_landmarks(frame, handLandmarks, handsModule.HAND_CONNECTIONS)\n",
    "                cv2.imshow('Test hand', frame)\n",
    "        #escape loop\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8478cf3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-i3ohmhl0\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f95056454b67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhands\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_hand_landmarks\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.2) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-i3ohmhl0\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#hands tracking with keypoints save!\n",
    "#make a video file\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V') #(*'XVID')\n",
    "out = cv2.VideoWriter('D:/MediaPipeHandTracking/Videotracking_output/output_75confidence.avi', fourcc, fps= 29.97, frameSize = (1440,1080))\n",
    "\n",
    "with handsModule.Hands(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.75, max_num_hands=8) as hands:\n",
    "     while (True):\n",
    " \n",
    "        ret, frame = capture.read()\n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    " \n",
    "        if results.multi_hand_landmarks != None:\n",
    "            for handLandmarks in results.multi_hand_landmarks:\n",
    "                for point in handsModule.HandLandmark:\n",
    " \n",
    "                    normalizedLandmark = handLandmarks.landmark[point]\n",
    "                    pixelCoordinatesLandmark = drawingModule._normalized_to_pixel_coordinates(normalizedLandmark.x, normalizedLandmark.y, frameWidth, frameHeight)\n",
    " \n",
    "                    cv2.circle(frame, pixelCoordinatesLandmark, 5, (0, 255, 0), -1)\n",
    "        \n",
    "        cv2.imshow('Test hand', frame)\n",
    "        out.write(frame) \n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "out.release()\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e7893ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shoes is not a valid model name for Objectron.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-22e8181e68c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                             \u001b[0mmax_num_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                             \u001b[0mmin_detection_confidence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                             model_name='Shoes') as objectron:\n\u001b[0m\u001b[0;32m     15\u001b[0m      \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\objectron.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, static_image_mode, max_num_objects, min_detection_confidence, min_tracking_confidence, model_name, focal_length, principal_point, image_size)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;31m# Create and init model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m     super().__init__(\n\u001b[0;32m    229\u001b[0m         \u001b[0mbinary_graph_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBINARYPB_FILE_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\objectron.py\u001b[0m in \u001b[0;36mget_model_by_name\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_model_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mObjectronModel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_MODEL_DICT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{name} is not a valid model name for Objectron.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m   \u001b[0m_download_oss_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MODEL_DICT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0m_MODEL_DICT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shoes is not a valid model name for Objectron."
     ]
    }
   ],
   "source": [
    "### OBJECTS (only allows for shoes, cups, chairs)\n",
    "#https://google.github.io/mediapipe/solutions/objectron.html\n",
    "#make a video file\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_objectron = mp.solutions.objectron\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V') #(*'XVID')\n",
    "out = cv2.VideoWriter('D:/MediaPipeHandTracking/Videotracking_output/outputobjecttracker.avi', fourcc, fps= 29.97, frameSize = (1440,1080))\n",
    "\n",
    "with mp_objectron.Objectron(static_image_mode=True,\n",
    "                            max_num_objects=3,\n",
    "                            min_detection_confidence=0.5,\n",
    "                            model_name='Shoe') as objectron:\n",
    "     while (True):\n",
    " \n",
    "        ret, frame = capture.read()\n",
    "        results = objectron.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    " \n",
    "              # Draw the box landmarks on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        if results.detected_objects:\n",
    "            for detected_object in results.detected_objects:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                  image, detected_object.landmarks_2d, mp_objectron.BOX_CONNECTIONS)\n",
    "                mp_drawing.draw_axis(image, detected_object.rotation,\n",
    "                                     detected_object.translation)\n",
    "        cv2.imshow('MediaPipe Objectron', image)\n",
    "        \n",
    "\n",
    "        out.write(image) \n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "out.release()\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87791538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
